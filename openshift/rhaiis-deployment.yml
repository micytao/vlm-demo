# Prerequisites:
# 1. Create docker-secret for pulling images from registry.redhat.io:
#    oc create secret generic docker-secret --from-file=.dockercfg=$HOME/.config/containers/auth.json --type=kubernetes.io/dockercfg -n rhaiis
#
# 2. Update the HF_TOKEN in the Secret below with your Hugging Face token
#
# 3. Ensure GPU time-slicing is configured (see gpu-time-slicing-config.yaml)

---
apiVersion: v1
kind: Namespace
metadata:
  name: rhaiis

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: rhaiis-cache
  namespace: rhaiis
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: gp3-csi

---
apiVersion: v1
kind: Secret
metadata:
  name: hf-secret
  namespace: rhaiis
type: Opaque
stringData:
  HF_TOKEN: "YOUR_HUGGINGFACE_TOKEN_HERE"  # Replace with your actual HF token

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rhaiis
  namespace: rhaiis
  labels:
    app: rhaiis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: rhaiis
  template:
    metadata:
      labels:
        app: rhaiis
    spec:
      imagePullSecrets:
        - name: docker-secret
      volumes:
        - name: cache-volume
          persistentVolumeClaim:
            claimName: rhaiis-cache
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: "8Gi"
      serviceAccountName: default
      containers:
        - name: rhaiis
          image: 'registry.redhat.io/rhaiis/vllm-cuda-rhel9:3.2.1'
          imagePullPolicy: IfNotPresent
          env:
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-secret
                  key: HF_TOKEN
            - name: HF_HUB_OFFLINE
              value: '0'
            - name: VLLM_NO_USAGE_STATS
              value: '1'
          command:
            - python
            - '-m'
            - vllm.entrypoints.openai.api_server
          args:
            - '--port=8000'
            - '--model=Qwen/Qwen2-VL-2B-Instruct'
            - '--tensor-parallel-size=1'
            - '--gpu-memory-utilization=0.4'
          ports:
            - containerPort: 8000
              protocol: TCP
          resources:
            limits:
              cpu: '16'
              nvidia.com/gpu: '1'
              memory: 48Gi
            requests:
              cpu: '4'
              memory: 12Gi
              nvidia.com/gpu: '1'
          volumeMounts:
            - name: cache-volume
              mountPath: /opt/app-root/src/.cache
            - name: shm
              mountPath: /dev/shm
          securityContext:
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              drop:
                - ALL
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
      restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: rhaiis-service
  namespace: rhaiis
  labels:
    app: rhaiis
spec:
  type: ClusterIP
  ports:
    - port: 8000
      targetPort: 8000
      protocol: TCP
      name: http
  selector:
    app: rhaiis

---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: rhaiis-route
  namespace: rhaiis
  labels:
    app: rhaiis
spec:
  port:
    targetPort: http
  to:
    kind: Service
    name: rhaiis-service
    weight: 100
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
  wildcardPolicy: None
